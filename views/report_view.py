import streamlit as st
import requests

# âœ… Falcon-7B-Instruct í…ìŠ¤íŠ¸ ìƒì„±ìš© API
API_URL = "https://api-inference.huggingface.co/models/tiiuae/falcon-7b-instruct"
headers = {
    "Authorization": "Bearer ",
    "Content-Type": "application/json"
}

# âœ… Falcon-7BëŠ” chat í˜•ì‹ì´ ì•„ë‹ˆë¼ text generationì´ë¯€ë¡œ promptë§Œ ì‚¬ìš©
def query(prompt):
    try:
        payload = {
            "inputs": prompt,
            "parameters": {
                "temperature": 0.7,
                "max_new_tokens": 512
            }
        }

        response = requests.post(API_URL, headers=headers, json=payload)
        response.raise_for_status()

        result = response.json()
        # âœ… Falcon ì‘ë‹µì€ {'generated_text': "..."} í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ì„
        if isinstance(result, list):
            return result[0].get("generated_text", "âš ï¸ ê²°ê³¼ ì—†ìŒ")
        else:
            return result.get("generated_text", "âš ï¸ ê²°ê³¼ ì—†ìŒ")

    except requests.exceptions.RequestException as e:
        return f"ìš”ì²­ ì‹¤íŒ¨: {e}"
    except requests.exceptions.JSONDecodeError:
        return f"âš ï¸ JSON ë””ì½”ë”© ì‹¤íŒ¨:\n{response.text}"

def render():
    st.subheader("ğŸ“„ ì •ì±… ë¦¬í¬íŠ¸ ìƒì„±")
    topic = st.text_input("ë¶„ì„ ì£¼ì œ ì…ë ¥", placeholder="ì˜ˆ: ê³ ë ¹í™” ëŒ€ì‘ ë°©ì•ˆ")

    if topic:
        with st.spinner("ğŸ§  GPT ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
            responder = GPTResponder()
            report = responder.ask(f"{topic}ì— ëŒ€í•œ ì „ë¼ë‚¨ë„ ë§ì¶¤í˜• ì •ì±… ì œì•ˆ ë¦¬í¬íŠ¸ ì‘ì„±í•´ì¤˜.")
            st.markdown(report)
